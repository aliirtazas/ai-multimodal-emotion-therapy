{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV and video path\n",
    "csv_path = r\"C:\\Users\\sanke\\Desktop\\Therapist_Model\\Segmentation Data\\Data\\Final Data\\Final_Conversation.csv\"\n",
    "video_path = r\"C:\\Users\\sanke\\Desktop\\Therapist_Model\\Segmentation Data\\Data\\Videos\\Telemental Health Mock Session.mp4\"\n",
    "final_conversation_df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Start    End Speaker                                               Text\n",
      "1  01:16  01:27  Client   And I'm a peer educator at CAPS here, and I t...\n",
      "3  01:53  02:08  Client   Um, so nothing much has changed in terms of w...\n",
      "4  02:08  02:21  Client   But as for the homework. I felt that sometime...\n",
      "5  02:22  02:33  Client   and my thoughts were like controlling me. So ...\n",
      "7  04:41  04:55  Client   So whenever I felt like my anxiety was throug...\n"
     ]
    }
   ],
   "source": [
    "# Filter only client timestamps\n",
    "client_df = final_conversation_df[final_conversation_df['Speaker'].str.lower() == 'client'].copy()\n",
    "print(client_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Start    End Speaker                                               Text  \\\n",
      "1  01:16  01:27  Client   And I'm a peer educator at CAPS here, and I t...   \n",
      "3  01:53  02:08  Client   Um, so nothing much has changed in terms of w...   \n",
      "4  02:08  02:21  Client   But as for the homework. I felt that sometime...   \n",
      "5  02:22  02:33  Client   and my thoughts were like controlling me. So ...   \n",
      "7  04:41  04:55  Client   So whenever I felt like my anxiety was throug...   \n",
      "\n",
      "   Start_sec  End_sec  Mid_sec  \n",
      "1         76       87     81.5  \n",
      "3        113      128    120.5  \n",
      "4        128      141    134.5  \n",
      "5        142      153    147.5  \n",
      "7        281      295    288.0  \n"
     ]
    }
   ],
   "source": [
    "# Convert MM:SS to seconds\n",
    "def time_to_seconds(t):\n",
    "    minutes, seconds = map(int, t.split(':'))\n",
    "    return minutes * 60 + seconds\n",
    "client_df['Start_sec'] = client_df['Start'].apply(time_to_seconds)\n",
    "client_df['End_sec'] = client_df['End'].apply(time_to_seconds)\n",
    "client_df['Mid_sec'] = (client_df['Start_sec'] + client_df['End_sec']) / 2\n",
    "print(client_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face detector (Haar Cascade)\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output directory\n",
    "output_dir = r\"C:\\Users\\sanke\\Desktop\\Therapist_Model\\Extracted_Faces\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ad7385576db457c9812606ddd53e4c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Video View:', options=('Gallery View', 'Speaker View'), style=DescriptionStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a508dc0f3224eafa742c6b09f28abe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Face Option:', options=(), style=DescriptionStyle(description_width='initial'), value=No…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Widgets for user selection\n",
    "view_dropdown = widgets.Dropdown(\n",
    "    options=['Gallery View', 'Speaker View'],\n",
    "    description='Video View:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "option_dropdown = widgets.Dropdown(\n",
    "    options=[],\n",
    "    description='Face Option:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "def update_option_dropdown(change):\n",
    "    if change['new'] == 'Gallery View':\n",
    "        option_dropdown.options = ['Left', 'Right']\n",
    "    elif change['new'] == 'Speaker View':\n",
    "        option_dropdown.options = ['Large', 'Small']\n",
    "\n",
    "view_dropdown.observe(update_option_dropdown, names='value')\n",
    "display(view_dropdown, option_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face_from_frame(frame, view_type, option, idx, target_size=(256, 256)):\n",
    "    h, w, _ = frame.shape\n",
    "\n",
    "    def save_resized_face(face, prefix):\n",
    "        resized_face = cv2.resize(face, target_size, interpolation=cv2.INTER_AREA)\n",
    "        path = os.path.join(output_dir, f\"{prefix}_{idx}.jpg\")\n",
    "        cv2.imwrite(path, resized_face)\n",
    "        return path\n",
    "\n",
    "    if view_type == 'Gallery View':\n",
    "        if option == 'Left':\n",
    "            half_img = frame[:, :w//2]\n",
    "            faces = face_cascade.detectMultiScale(half_img, 1.3, 5)\n",
    "            if len(faces) == 1:\n",
    "                x, y, fw, fh = faces[0]\n",
    "                face = half_img[y:y+fh, x:x+fw]\n",
    "                return save_resized_face(face, \"left\")\n",
    "        elif option == 'Right':\n",
    "            half_img = frame[:, w//2:]\n",
    "            faces = face_cascade.detectMultiScale(half_img, 1.3, 5)\n",
    "            if len(faces) == 1:\n",
    "                x, y, fw, fh = faces[0]\n",
    "                face = half_img[y:y+fh, x:x+fw]\n",
    "                return save_resized_face(face, \"right\")\n",
    "\n",
    "    elif view_type == 'Speaker View':\n",
    "        faces = face_cascade.detectMultiScale(frame, 1.3, 5)\n",
    "        if len(faces) == 2:\n",
    "            face_areas = [(fw * fh, (x, y, fw, fh)) for (x, y, fw, fh) in faces]\n",
    "            face_areas.sort(reverse=True)\n",
    "            if option == 'Large':\n",
    "                (xL, yL, fwL, fhL) = face_areas[0][1]\n",
    "                face = frame[yL:yL+fhL, xL:xL+fwL]\n",
    "                return save_resized_face(face, \"large\")\n",
    "            elif option == 'Small':\n",
    "                (xS, yS, fwS, fhS) = face_areas[1][1]\n",
    "                face = frame[yS:yS+fhS, xS:xS+fwS]\n",
    "                return save_resized_face(face, \"small\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(change):\n",
    "    view_type = view_dropdown.value\n",
    "    option = option_dropdown.value\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    for idx, row in client_df.iterrows():\n",
    "        cap.set(cv2.CAP_PROP_POS_MSEC, row['Mid_sec'] * 1000)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "\n",
    "        path = extract_face_from_frame(frame, view_type, option, idx)\n",
    "        if path:\n",
    "            client_df.loc[idx, 'Image_Path'] = path\n",
    "\n",
    "    cap.release()\n",
    "    print(client_df[['Start', 'End', 'Speaker', 'Image_Path']])\n",
    "\n",
    "option_dropdown.observe(process_video, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Image_Path'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\sanke\\anaconda3\\envs\\NLP_Project\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Image_Path'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m     final_conversation_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImage_Path\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m client_df\u001b[38;5;241m.\u001b[39mindex:\n\u001b[1;32m----> 5\u001b[0m     final_conversation_df\u001b[38;5;241m.\u001b[39mat[idx, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImage_Path\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mclient_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mat\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mImage_Path\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      6\u001b[0m post_extraction_df \u001b[38;5;241m=\u001b[39m final_conversation_df\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(post_extraction_df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32mc:\\Users\\sanke\\anaconda3\\envs\\NLP_Project\\lib\\site-packages\\pandas\\core\\indexing.py:2575\u001b[0m, in \u001b[0;36m_AtIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2572\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid call for scalar access (getting)!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2573\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mloc[key]\n\u001b[1;32m-> 2575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sanke\\anaconda3\\envs\\NLP_Project\\lib\\site-packages\\pandas\\core\\indexing.py:2527\u001b[0m, in \u001b[0;36m_ScalarAccessIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2524\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid call for scalar access (getting)!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2526\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_key(key)\n\u001b[1;32m-> 2527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_takeable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sanke\\anaconda3\\envs\\NLP_Project\\lib\\site-packages\\pandas\\core\\frame.py:4214\u001b[0m, in \u001b[0;36mDataFrame._get_value\u001b[1;34m(self, index, col, takeable)\u001b[0m\n\u001b[0;32m   4211\u001b[0m     series \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ixs(col, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   4212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m series\u001b[38;5;241m.\u001b[39m_values[index]\n\u001b[1;32m-> 4214\u001b[0m series \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_item_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4215\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_engine\n\u001b[0;32m   4217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, MultiIndex):\n\u001b[0;32m   4218\u001b[0m     \u001b[38;5;66;03m# CategoricalIndex: Trying to use the engine fastpath may give incorrect\u001b[39;00m\n\u001b[0;32m   4219\u001b[0m     \u001b[38;5;66;03m#  results if our categories are integers that dont match our codes\u001b[39;00m\n\u001b[0;32m   4220\u001b[0m     \u001b[38;5;66;03m# IntervalIndex: IntervalTree has no get_loc\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sanke\\anaconda3\\envs\\NLP_Project\\lib\\site-packages\\pandas\\core\\frame.py:4638\u001b[0m, in \u001b[0;36mDataFrame._get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   4633\u001b[0m res \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mget(item)\n\u001b[0;32m   4634\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4635\u001b[0m     \u001b[38;5;66;03m# All places that call _get_item_cache have unique columns,\u001b[39;00m\n\u001b[0;32m   4636\u001b[0m     \u001b[38;5;66;03m#  pending resolution of GH#33047\u001b[39;00m\n\u001b[1;32m-> 4638\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4639\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ixs(loc, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   4641\u001b[0m     cache[item] \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[1;32mc:\\Users\\sanke\\anaconda3\\envs\\NLP_Project\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Image_Path'"
     ]
    }
   ],
   "source": [
    "# Updating the original Dataframe\n",
    "if 'Image_Path' not in final_conversation_df.columns:\n",
    "    final_conversation_df['Image_Path'] = None\n",
    "for idx in client_df.index:\n",
    "    final_conversation_df.at[idx, 'Image_Path'] = client_df.at[idx, 'Image_Path']\n",
    "post_extraction_df = final_conversation_df.copy()\n",
    "print(post_extraction_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
