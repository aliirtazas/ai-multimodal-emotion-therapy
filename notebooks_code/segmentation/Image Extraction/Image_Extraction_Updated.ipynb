{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV and video path\n",
    "csv_path = r\"C:\\\\Users\\\\sanke\\\\Desktop\\\\Therapist_Model\\\\Segmentation Data\\\\Data\\\\Final Data\\\\Final_Conversation.csv\"\n",
    "video_path = r\"C:\\\\Users\\\\sanke\\\\Desktop\\\\Therapist_Model\\\\Segmentation Data\\\\Data\\\\Videos\\\\Telemental Health Mock Session.mp4\"\n",
    "final_conversation_df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01:16</td>\n",
       "      <td>01:27</td>\n",
       "      <td>Client</td>\n",
       "      <td>And I'm a peer educator at CAPS here, and I t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01:53</td>\n",
       "      <td>02:08</td>\n",
       "      <td>Client</td>\n",
       "      <td>Um, so nothing much has changed in terms of w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02:08</td>\n",
       "      <td>02:21</td>\n",
       "      <td>Client</td>\n",
       "      <td>But as for the homework. I felt that sometime...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>02:22</td>\n",
       "      <td>02:33</td>\n",
       "      <td>Client</td>\n",
       "      <td>and my thoughts were like controlling me. So ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>04:41</td>\n",
       "      <td>04:55</td>\n",
       "      <td>Client</td>\n",
       "      <td>So whenever I felt like my anxiety was throug...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Start    End Speaker                                               Text\n",
       "1  01:16  01:27  Client   And I'm a peer educator at CAPS here, and I t...\n",
       "3  01:53  02:08  Client   Um, so nothing much has changed in terms of w...\n",
       "4  02:08  02:21  Client   But as for the homework. I felt that sometime...\n",
       "5  02:22  02:33  Client   and my thoughts were like controlling me. So ...\n",
       "7  04:41  04:55  Client   So whenever I felt like my anxiety was throug..."
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter only client timestamps\n",
    "client_df = final_conversation_df[final_conversation_df['Speaker'].str.lower() == 'client'].copy()\n",
    "client_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert MM:SS to seconds\n",
    "def time_to_seconds(t):\n",
    "    minutes, seconds = map(int, t.split(':'))\n",
    "    return minutes * 60 + seconds\n",
    "client_df['Start_sec'] = client_df['Start'].apply(time_to_seconds)\n",
    "client_df['End_sec'] = client_df['End'].apply(time_to_seconds)\n",
    "client_df['Mid_sec'] = (client_df['Start_sec'] + client_df['End_sec']) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face detector\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output directory\n",
    "output_dir = r\"C:\\\\Users\\\\sanke\\\\Desktop\\\\Therapist_Model\\\\Extracted_Faces\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abd1519f3d934007aea8e8457c14e4b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Video View:', options=('', 'Gallery View', 'Speaker View'), style=DescriptionStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11c6fb700f0d435ca47ebfc3ddbd3c29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Face Option:', options=('',), style=DescriptionStyle(description_width='initial'), value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0543acdde1741f1b53308d48972e4ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Confirm Selection', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ecdc77af49942888f833cb09dc10909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dropdown widgets\n",
    "view_dropdown = widgets.Dropdown(\n",
    "    options=['', 'Gallery View', 'Speaker View'],\n",
    "    description='Video View:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "option_dropdown = widgets.Dropdown(\n",
    "    options=[''],\n",
    "    description='Face Option:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "confirm_button = widgets.Button(description=\"Confirm Selection\", button_style='success')\n",
    "output_area = widgets.Output()\n",
    "\n",
    "def update_option_dropdown(change):\n",
    "    if change['new'] == 'Gallery View':\n",
    "        option_dropdown.options = ['', 'Left', 'Right']\n",
    "    elif change['new'] == 'Speaker View':\n",
    "        option_dropdown.options = ['', 'Large', 'Small']\n",
    "    else:\n",
    "        option_dropdown.options = ['']\n",
    "view_dropdown.observe(update_option_dropdown, names='value')\n",
    "\n",
    "def confirm_selection(b):\n",
    "    selected_view['value'] = view_dropdown.value\n",
    "    selected_option['value'] = option_dropdown.value\n",
    "    with output_area:\n",
    "        clear_output()\n",
    "        if selected_view['value'] and selected_option['value']:\n",
    "            print(f\"Selected View: {selected_view['value']} | Selected Option: {selected_option['value']}\")\n",
    "        else:\n",
    "            print(\"Please make selections in both dropdowns.\")\n",
    "\n",
    "confirm_button.on_click(confirm_selection)\n",
    "\n",
    "display(view_dropdown, option_dropdown, confirm_button, output_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face extraction function\n",
    "def extract_face_from_frame(frame, view_type, option, idx, target_size=(256, 256)):\n",
    "    h, w, _ = frame.shape\n",
    "\n",
    "    def save_resized_face(face, prefix):\n",
    "        resized_face = cv2.resize(face, target_size, interpolation=cv2.INTER_AREA)\n",
    "        path = os.path.join(output_dir, f\"{prefix}_{idx}.jpg\")\n",
    "        cv2.imwrite(path, resized_face)\n",
    "        return path\n",
    "\n",
    "    if view_type == 'Gallery View':\n",
    "        if option == 'Left':\n",
    "            half_img = frame[:, :w//2]\n",
    "            faces = face_cascade.detectMultiScale(half_img, 1.3, 5)\n",
    "            if len(faces) == 1:\n",
    "                x, y, fw, fh = faces[0]\n",
    "                face = half_img[y:y+fh, x:x+fw]\n",
    "                return save_resized_face(face, \"left\")\n",
    "        elif option == 'Right':\n",
    "            half_img = frame[:, w//2:]\n",
    "            faces = face_cascade.detectMultiScale(half_img, 1.3, 5)\n",
    "            if len(faces) == 1:\n",
    "                x, y, fw, fh = faces[0]\n",
    "                face = half_img[y:y+fh, x:x+fw]\n",
    "                return save_resized_face(face, \"right\")\n",
    "\n",
    "    elif view_type == 'Speaker View':\n",
    "        faces = face_cascade.detectMultiScale(frame, 1.3, 5)\n",
    "        if len(faces) == 2:\n",
    "            face_areas = [(fw * fh, (x, y, fw, fh)) for (x, y, fw, fh) in faces]\n",
    "            face_areas.sort(reverse=True)\n",
    "            if option == 'Large':\n",
    "                (xL, yL, fwL, fhL) = face_areas[0][1]\n",
    "                face = frame[yL:yL+fhL, xL:xL+fwL]\n",
    "                return save_resized_face(face, \"large\")\n",
    "            elif option == 'Small':\n",
    "                (xS, yS, fwS, fhS) = face_areas[1][1]\n",
    "                face = frame[yS:yS+fhS, xS:xS+fwS]\n",
    "                return save_resized_face(face, \"small\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing with: Gallery View - Left\n",
      "Done! Showing result:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Text</th>\n",
       "      <th>Image_Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:01</td>\n",
       "      <td>01:16</td>\n",
       "      <td>therapist</td>\n",
       "      <td>All right, hi everybody. My name is Daniel Ga...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01:16</td>\n",
       "      <td>01:27</td>\n",
       "      <td>Client</td>\n",
       "      <td>And I'm a peer educator at CAPS here, and I t...</td>\n",
       "      <td>C:\\\\Users\\\\sanke\\\\Desktop\\\\Therapist_Model\\\\Ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01:27</td>\n",
       "      <td>01:53</td>\n",
       "      <td>therapist</td>\n",
       "      <td>All right, so we're going to go ahead and div...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01:53</td>\n",
       "      <td>02:08</td>\n",
       "      <td>Client</td>\n",
       "      <td>Um, so nothing much has changed in terms of w...</td>\n",
       "      <td>C:\\\\Users\\\\sanke\\\\Desktop\\\\Therapist_Model\\\\Ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02:08</td>\n",
       "      <td>02:21</td>\n",
       "      <td>Client</td>\n",
       "      <td>But as for the homework. I felt that sometime...</td>\n",
       "      <td>C:\\\\Users\\\\sanke\\\\Desktop\\\\Therapist_Model\\\\Ex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Start    End    Speaker                                               Text  \\\n",
       "0  00:01  01:16  therapist   All right, hi everybody. My name is Daniel Ga...   \n",
       "1  01:16  01:27     Client   And I'm a peer educator at CAPS here, and I t...   \n",
       "2  01:27  01:53  therapist   All right, so we're going to go ahead and div...   \n",
       "3  01:53  02:08     Client   Um, so nothing much has changed in terms of w...   \n",
       "4  02:08  02:21     Client   But as for the homework. I felt that sometime...   \n",
       "\n",
       "                                          Image_Path  \n",
       "0                                               None  \n",
       "1  C:\\\\Users\\\\sanke\\\\Desktop\\\\Therapist_Model\\\\Ex...  \n",
       "2                                               None  \n",
       "3  C:\\\\Users\\\\sanke\\\\Desktop\\\\Therapist_Model\\\\Ex...  \n",
       "4  C:\\\\Users\\\\sanke\\\\Desktop\\\\Therapist_Model\\\\Ex...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Processing code to be run after selection\n",
    "if selected_view['value'] is None or selected_option['value'] is None:\n",
    "    print(\"Please select both dropdown values before processing.\")\n",
    "else:\n",
    "    print(f\"Processing with: {selected_view['value']} - {selected_option['value']}\")\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    for idx, row in client_df.iterrows():\n",
    "        cap.set(cv2.CAP_PROP_POS_MSEC, row['Mid_sec'] * 1000)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "\n",
    "        path = extract_face_from_frame(frame, selected_view['value'], selected_option['value'], idx)\n",
    "        if path:\n",
    "            client_df.loc[idx, 'Image_Path'] = path\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if 'Image_Path' not in final_conversation_df.columns:\n",
    "        final_conversation_df['Image_Path'] = None\n",
    "    for idx in client_df.index:\n",
    "        final_conversation_df.at[idx, 'Image_Path'] = client_df.at[idx, 'Image_Path']\n",
    "\n",
    "    post_extraction_df = final_conversation_df.copy()\n",
    "    print(\"Done! Showing result:\")\n",
    "    display(post_extraction_df[['Start', 'End', 'Speaker', 'Text', 'Image_Path']].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
