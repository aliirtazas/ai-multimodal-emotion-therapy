{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195a2276",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\n",
      "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
      "INFO:datasets:PyTorch version 2.6.0+cu118 available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "CUDA Version: 11.8\n",
      "Torch Version: 2.6.0+cu118\n",
      "Device Name: NVIDIA GeForce RTX 4070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from moviepy import *\n",
    "import whisperx\n",
    "import os\n",
    "import pandas as pd\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset\n",
    "import joblib\n",
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets\n",
    "import shutil\n",
    "import torch.nn as nn\n",
    "from transformers import DebertaV2TokenizerFast, DebertaV2ForSequenceClassification\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"CUDA Version:\", torch.version.cuda)\n",
    "print(\"Torch Version:\", torch.__version__)\n",
    "print(\"Device Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No CUDA\")\n",
    "\n",
    "# Seting the device to CUDA if available\n",
    "device = torch.device(\"cuda\")\n",
    "assert torch.cuda.is_available(), \"CUDA GPU is not available. Please check your setup.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f0f98d",
   "metadata": {},
   "source": [
    "### Transcription & Speaker Diarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a38481a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'mp42', 'minor_version': '0', 'compatible_brands': 'isommp42', 'creation_time': '2023-02-25T20:14:20.000000Z'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [640, 360], 'bitrate': 139, 'fps': 25.0, 'codec_name': 'h264', 'profile': '(Main)', 'metadata': {'Metadata': '', 'creation_time': '2023-02-25T20:14:20.000000Z', 'handler_name': 'ISO Media file produced by Google Inc. Created on: 02/25/2023.', 'vendor_id': '[0][0][0][0]'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': None, 'default': True, 'fps': 44100, 'bitrate': 127, 'metadata': {'Metadata': '', 'creation_time': '2023-02-25T20:14:20.000000Z', 'handler_name': 'ISO Media file produced by Google Inc. Created on: 02/25/2023.', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 884.1, 'bitrate': 270, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'h264', 'video_profile': '(Main)', 'video_size': [640, 360], 'video_bitrate': 139, 'video_fps': 25.0, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 44100, 'audio_bitrate': 127, 'video_duration': 884.1, 'video_n_frames': 22102}\n",
      "c:\\Users\\aliir\\anaconda3\\envs\\whisperx\\lib\\site-packages\\imageio_ffmpeg\\binaries\\ffmpeg-win-x86_64-v7.1.exe -i D:\\Data Science Projects\\AI Emotion Analysis\\segmentation\\Telemental Health Mock Session.mp4 -loglevel error -f image2pipe -vf scale=640:360 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n",
      "MoviePy - Writing audio in D:\\Data Science Projects\\AI Emotion Analysis\\segmentation\\Telemental Health Mock Session.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "No language specified, language will be first be detected for each audio file (increases inference time).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aliir\\anaconda3\\envs\\whisperx\\lib\\inspect.py:869: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
      "  if ismodule(module) and hasattr(module, '__file__'):\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.5.1. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint c:\\Users\\aliir\\anaconda3\\envs\\whisperx\\lib\\site-packages\\whisperx\\assets\\pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.2. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.6.0+cu118. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aliir\\anaconda3\\envs\\whisperx\\lib\\site-packages\\pyannote\\audio\\utils\\reproducibility.py:74: ReproducibilityWarning: TensorFloat-32 (TF32) has been disabled as it might lead to reproducibility issues and lower accuracy.\n",
      "It can be re-enabled by calling\n",
      "   >>> import torch\n",
      "   >>> torch.backends.cuda.matmul.allow_tf32 = True\n",
      "   >>> torch.backends.cudnn.allow_tf32 = True\n",
      "See https://github.com/pyannote/pyannote-audio/issues/1370 for more details.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: en (1.00) in first 30s of audio...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aliir\\anaconda3\\envs\\whisperx\\lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1831.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    }
   ],
   "source": [
    "def extract_audio(video_path):\n",
    "    base = os.path.splitext(video_path)[0]\n",
    "    audio_output_path = base + \".wav\"\n",
    "    video = VideoFileClip(video_path)\n",
    "    video.audio.write_audiofile(audio_output_path)\n",
    "    return audio_output_path\n",
    "\n",
    "def transcribe_and_diarize(video_path, hf_token, whisper_model=\"large-v2\", device=\"cuda\"):\n",
    "    audio_path = extract_audio(video_path)\n",
    "\n",
    "    model = whisperx.load_model(whisper_model, device=device, compute_type=\"float16\")\n",
    "    diarize_model = whisperx.DiarizationPipeline(use_auth_token=hf_token, device=device)\n",
    "\n",
    "    result = model.transcribe(audio_path, chunk_size=15)\n",
    "    diarization_result = diarize_model(audio_path)\n",
    "    result = whisperx.assign_word_speakers(diarization_result, result)\n",
    "\n",
    "    data = []\n",
    "    for segment in result[\"segments\"]:\n",
    "        speaker = segment.get(\"speaker\", \"Unknown\")\n",
    "        text = segment[\"text\"]\n",
    "        start_time_sec = segment[\"start\"]\n",
    "        end_time_sec = segment[\"end\"]\n",
    "        data.append([start_time_sec, end_time_sec, speaker, text])\n",
    "\n",
    "    df = pd.DataFrame(data, columns=[\"Start (sec)\", \"End (sec)\", \"Speaker\", \"Text\"])\n",
    "    df[\"total_duration\"] = df[\"End (sec)\"] - df[\"Start (sec)\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "video_path = r\"D:\\Data Science Projects Github\\ai-multimodal-emotion-therapy\\notebooks_code\\segmentation\\videos\\Telemental Health Mock Session.mp4\"\n",
    "hf_token = \"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\"\n",
    "\n",
    "transcript_df = transcribe_and_diarize(video_path, hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03433168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start (sec)</th>\n",
       "      <th>End (sec)</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Text</th>\n",
       "      <th>total_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.837</td>\n",
       "      <td>10.055</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>All right, hi everybody. My name is Daniel Ga...</td>\n",
       "      <td>8.218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.055</td>\n",
       "      <td>19.454</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>Today I am joined by a fellow student here on...</td>\n",
       "      <td>9.399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.454</td>\n",
       "      <td>30.440</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>The purpose of this recording is to try to sh...</td>\n",
       "      <td>10.986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.440</td>\n",
       "      <td>44.497</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>the foreseeable future, and we understand tha...</td>\n",
       "      <td>14.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.497</td>\n",
       "      <td>52.580</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>So I'm going to allow Prita to introduce hers...</td>\n",
       "      <td>8.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>826.636</td>\n",
       "      <td>833.740</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>Yeah, I will definitely try to practice it, a...</td>\n",
       "      <td>7.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>834.196</td>\n",
       "      <td>846.700</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>Give it a couple of tries, okay? Again, it's ...</td>\n",
       "      <td>12.504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>846.953</td>\n",
       "      <td>861.871</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>completely different from the square breathin...</td>\n",
       "      <td>14.918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>861.871</td>\n",
       "      <td>868.486</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>The tools that we're currently lacking to hel...</td>\n",
       "      <td>6.615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>869.245</td>\n",
       "      <td>882.712</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>Good, so let's make that homework. Keep using...</td>\n",
       "      <td>13.467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Start (sec)  End (sec)     Speaker  \\\n",
       "0         1.837     10.055  SPEAKER_00   \n",
       "1        10.055     19.454  SPEAKER_00   \n",
       "2        19.454     30.440  SPEAKER_00   \n",
       "3        30.440     44.497  SPEAKER_00   \n",
       "4        44.497     52.580  SPEAKER_00   \n",
       "..          ...        ...         ...   \n",
       "69      826.636    833.740  SPEAKER_01   \n",
       "70      834.196    846.700  SPEAKER_00   \n",
       "71      846.953    861.871  SPEAKER_00   \n",
       "72      861.871    868.486  SPEAKER_00   \n",
       "73      869.245    882.712  SPEAKER_00   \n",
       "\n",
       "                                                 Text  total_duration  \n",
       "0    All right, hi everybody. My name is Daniel Ga...           8.218  \n",
       "1    Today I am joined by a fellow student here on...           9.399  \n",
       "2    The purpose of this recording is to try to sh...          10.986  \n",
       "3    the foreseeable future, and we understand tha...          14.057  \n",
       "4    So I'm going to allow Prita to introduce hers...           8.083  \n",
       "..                                                ...             ...  \n",
       "69   Yeah, I will definitely try to practice it, a...           7.104  \n",
       "70   Give it a couple of tries, okay? Again, it's ...          12.504  \n",
       "71   completely different from the square breathin...          14.918  \n",
       "72   The tools that we're currently lacking to hel...           6.615  \n",
       "73   Good, so let's make that homework. Keep using...          13.467  \n",
       "\n",
       "[74 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c747bea",
   "metadata": {},
   "source": [
    "### Predicting Speakers from Text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381b02a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f13e20c69442f6aa6cd357a2cd7833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/63 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bcfd8563b1d48f793b3a4d07f9310bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model components\n",
    "def load_speaker_model(model_dir, device):\n",
    "    model = RobertaForSequenceClassification.from_pretrained(model_dir).to(device)\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(model_dir)\n",
    "    label_encoder = joblib.load(os.path.join(model_dir, \"label_encoder.pkl\"))\n",
    "    model.eval()\n",
    "    return model, tokenizer, label_encoder\n",
    "\n",
    "# Predict speaker label\n",
    "def predict_speaker_class(df_subset, model, tokenizer, label_encoder, device):\n",
    "    dataset = Dataset.from_pandas(df_subset[[\"Text\"]].rename(columns={\"Text\": \"utterance\"}))\n",
    "    dataset = dataset.map(lambda x: tokenizer(x[\"utterance\"], padding=\"max_length\", truncation=True, max_length=512), batched=True)\n",
    "    dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "    loader = DataLoader(dataset, batch_size=16)\n",
    "\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            preds = torch.argmax(outputs.logits, axis=-1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "\n",
    "    return label_encoder.inverse_transform(all_preds)\n",
    "\n",
    "# Classify and relabel speakers\n",
    "def classify_and_map_speakers(df, model, tokenizer, label_encoder, device):\n",
    "    speaker_00_df = df[df[\"Speaker\"] == \"SPEAKER_00\"].copy()\n",
    "    speaker_00_preds = predict_speaker_class(speaker_00_df, model, tokenizer, label_encoder, device)\n",
    "    speaker_00_df[\"Predicted\"] = speaker_00_preds\n",
    "    majority_00 = speaker_00_df[\"Predicted\"].value_counts().idxmax()\n",
    "    percent_00 = (speaker_00_df[\"Predicted\"].value_counts()[majority_00] / len(speaker_00_df)) * 100\n",
    "\n",
    "    speaker_01_df = df[df[\"Speaker\"] == \"SPEAKER_01\"].copy()\n",
    "    speaker_01_preds = predict_speaker_class(speaker_01_df, model, tokenizer, label_encoder, device)\n",
    "    speaker_01_df[\"Predicted\"] = speaker_01_preds\n",
    "    majority_01 = speaker_01_df[\"Predicted\"].value_counts().idxmax()\n",
    "    percent_01 = (speaker_01_df[\"Predicted\"].value_counts()[majority_01] / len(speaker_01_df)) * 100\n",
    "\n",
    "    if percent_00 > percent_01:\n",
    "        speaker_map = {\n",
    "            \"SPEAKER_00\": majority_00,\n",
    "            \"SPEAKER_01\": \"therapist\" if majority_00.lower() == \"client\" else \"client\"\n",
    "        }\n",
    "    else:\n",
    "        speaker_map = {\n",
    "            \"SPEAKER_01\": majority_01,\n",
    "            \"SPEAKER_00\": \"therapist\" if majority_01.lower() == \"client\" else \"client\"\n",
    "        }\n",
    "\n",
    "    return df.copy().replace({\"Speaker\": speaker_map})\n",
    "\n",
    "# Convert seconds to MM:SS\n",
    "def sec_to_min_sec(seconds):\n",
    "    minutes = int(seconds) // 60\n",
    "    seconds = int(seconds) % 60\n",
    "    return f\"{minutes:02d}:{seconds:02d}\"\n",
    "\n",
    "# Merge therapist segments\n",
    "def merge_conversation_segments(df):\n",
    "    merged_data = []\n",
    "    current_speaker = df.loc[0, 'Speaker']\n",
    "    current_start = df.loc[0, 'Start (sec)']\n",
    "    current_end = df.loc[0, 'End (sec)']\n",
    "    current_text = df.loc[0, 'Text']\n",
    "\n",
    "    for i in range(1, len(df)):\n",
    "        row = df.loc[i]\n",
    "        speaker = row['Speaker']\n",
    "        if speaker == \"therapist\" and current_speaker == \"therapist\":\n",
    "            current_end = row['End (sec)']\n",
    "            current_text += \" \" + row['Text']\n",
    "        else:\n",
    "            merged_data.append({\n",
    "                'Start': sec_to_min_sec(current_start),\n",
    "                'End': sec_to_min_sec(current_end),\n",
    "                'Speaker': current_speaker,\n",
    "                'Text': current_text\n",
    "            })\n",
    "            current_speaker = speaker\n",
    "            current_start = row['Start (sec)']\n",
    "            current_end = row['End (sec)']\n",
    "            current_text = row['Text']\n",
    "\n",
    "    merged_data.append({\n",
    "        'Start': sec_to_min_sec(current_start),\n",
    "        'End': sec_to_min_sec(current_end),\n",
    "        'Speaker': current_speaker,\n",
    "        'Text': current_text\n",
    "    })\n",
    "\n",
    "    return pd.DataFrame(merged_data)\n",
    "\n",
    "\n",
    "model_dir = r\"D:\\Data Science Projects Github\\ai-multimodal-emotion-therapy\\models\\speaker_prediction_roberta_model\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Loading model components\n",
    "model, tokenizer, label_encoder = load_speaker_model(model_dir, device)\n",
    "\n",
    "# Re-map generic speakers to \"client\" or \"therapist\"\n",
    "updated_df = classify_and_map_speakers(transcript_df, model, tokenizer, label_encoder, device)\n",
    "\n",
    "# Merge therapist blocks and return the final conversation format\n",
    "final_conversation_df = merge_conversation_segments(updated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb907823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:01</td>\n",
       "      <td>01:16</td>\n",
       "      <td>therapist</td>\n",
       "      <td>All right, hi everybody. My name is Daniel Ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01:16</td>\n",
       "      <td>01:27</td>\n",
       "      <td>Client</td>\n",
       "      <td>And I'm a peer educator at CAPS here, and I t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01:27</td>\n",
       "      <td>01:53</td>\n",
       "      <td>therapist</td>\n",
       "      <td>All right, so we're going to go ahead and div...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01:53</td>\n",
       "      <td>02:08</td>\n",
       "      <td>Client</td>\n",
       "      <td>Um, so nothing much has changed in terms of w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02:08</td>\n",
       "      <td>02:21</td>\n",
       "      <td>Client</td>\n",
       "      <td>But as for the homework. I felt that sometime...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>02:22</td>\n",
       "      <td>02:33</td>\n",
       "      <td>Client</td>\n",
       "      <td>and my thoughts were like controlling me. So ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>02:33</td>\n",
       "      <td>04:40</td>\n",
       "      <td>therapist</td>\n",
       "      <td>the same thing going on every day, right? Rig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>04:41</td>\n",
       "      <td>04:55</td>\n",
       "      <td>Client</td>\n",
       "      <td>So whenever I felt like my anxiety was throug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>04:56</td>\n",
       "      <td>05:08</td>\n",
       "      <td>Client</td>\n",
       "      <td>Like emails from my college about my GPA, fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>05:09</td>\n",
       "      <td>05:37</td>\n",
       "      <td>therapist</td>\n",
       "      <td>And it just like builds up so I can't even co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>05:38</td>\n",
       "      <td>05:52</td>\n",
       "      <td>Client</td>\n",
       "      <td>distract myself from like the initial thing t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>05:53</td>\n",
       "      <td>06:04</td>\n",
       "      <td>Client</td>\n",
       "      <td>tempted to like check whatever all the media ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>06:04</td>\n",
       "      <td>06:12</td>\n",
       "      <td>Client</td>\n",
       "      <td>racing. My thoughts are keep racing with ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>06:12</td>\n",
       "      <td>09:52</td>\n",
       "      <td>therapist</td>\n",
       "      <td>But I can't help it. Yeah, it almost sounds l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>09:53</td>\n",
       "      <td>10:04</td>\n",
       "      <td>Client</td>\n",
       "      <td>to myself in front of a mirror. And honestly,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10:05</td>\n",
       "      <td>13:45</td>\n",
       "      <td>therapist</td>\n",
       "      <td>Yeah. It's kind of weird. Yeah. Honestly, it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13:46</td>\n",
       "      <td>13:53</td>\n",
       "      <td>Client</td>\n",
       "      <td>Yeah, I will definitely try to practice it, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>13:54</td>\n",
       "      <td>14:42</td>\n",
       "      <td>therapist</td>\n",
       "      <td>Give it a couple of tries, okay? Again, it's ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Start    End    Speaker                                               Text\n",
       "0   00:01  01:16  therapist   All right, hi everybody. My name is Daniel Ga...\n",
       "1   01:16  01:27     Client   And I'm a peer educator at CAPS here, and I t...\n",
       "2   01:27  01:53  therapist   All right, so we're going to go ahead and div...\n",
       "3   01:53  02:08     Client   Um, so nothing much has changed in terms of w...\n",
       "4   02:08  02:21     Client   But as for the homework. I felt that sometime...\n",
       "5   02:22  02:33     Client   and my thoughts were like controlling me. So ...\n",
       "6   02:33  04:40  therapist   the same thing going on every day, right? Rig...\n",
       "7   04:41  04:55     Client   So whenever I felt like my anxiety was throug...\n",
       "8   04:56  05:08     Client   Like emails from my college about my GPA, fro...\n",
       "9   05:09  05:37  therapist   And it just like builds up so I can't even co...\n",
       "10  05:38  05:52     Client   distract myself from like the initial thing t...\n",
       "11  05:53  06:04     Client   tempted to like check whatever all the media ...\n",
       "12  06:04  06:12     Client   racing. My thoughts are keep racing with ever...\n",
       "13  06:12  09:52  therapist   But I can't help it. Yeah, it almost sounds l...\n",
       "14  09:53  10:04     Client   to myself in front of a mirror. And honestly,...\n",
       "15  10:05  13:45  therapist   Yeah. It's kind of weird. Yeah. Honestly, it ...\n",
       "16  13:46  13:53     Client   Yeah, I will definitely try to practice it, a...\n",
       "17  13:54  14:42  therapist   Give it a couple of tries, okay? Again, it's ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_conversation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4602f81",
   "metadata": {},
   "source": [
    "### Image Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be35301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88e6728d084046d7b18931b2eda173e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Video View:', options=('', 'Gallery View', 'Speaker View'), style=DescriptionStyle(descr‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16aeb08ab54a43cca00c0d5fb78fb82b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Face Option:', options=('',), style=DescriptionStyle(description_width='initial'), value‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "901ed10a73bd45118619f7faa161aac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Confirm Selection', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e56d4e6b36e4ced845dda2e300c25d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize Haar cascade\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "def time_to_seconds(t):\n",
    "    minutes, seconds = map(int, t.split(':'))\n",
    "    return minutes * 60 + seconds\n",
    "\n",
    "def prepare_client_df(conversation_df):\n",
    "    client_df = conversation_df[conversation_df['Speaker'].str.lower() == 'client'].copy()\n",
    "    client_df['Start_sec'] = client_df['Start'].apply(time_to_seconds)\n",
    "    client_df['End_sec'] = client_df['End'].apply(time_to_seconds)\n",
    "    client_df['Mid_sec'] = (client_df['Start_sec'] + client_df['End_sec']) / 2\n",
    "    return client_df\n",
    "\n",
    "def setup_output_folder(output_dir):\n",
    "    if os.path.exists(output_dir):\n",
    "        shutil.rmtree(output_dir)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def extract_face_from_frame(frame, view_type, option, idx, output_dir, target_size=(256, 256)):\n",
    "    h, w, _ = frame.shape\n",
    "\n",
    "    def save_resized_face(face, prefix):\n",
    "        resized_face = cv2.resize(face, target_size, interpolation=cv2.INTER_AREA)\n",
    "        path = os.path.join(output_dir, f\"{prefix}_{idx}.jpg\")\n",
    "        cv2.imwrite(path, resized_face)\n",
    "        return path\n",
    "\n",
    "    if view_type == 'Gallery View':\n",
    "        if option == 'Left':\n",
    "            half_img = frame[:, :w//2]\n",
    "            faces = face_cascade.detectMultiScale(half_img, 1.3, 5)\n",
    "            if len(faces) == 1:\n",
    "                x, y, fw, fh = faces[0]\n",
    "                return save_resized_face(half_img[y:y+fh, x:x+fw], \"left\")\n",
    "        elif option == 'Right':\n",
    "            half_img = frame[:, w//2:]\n",
    "            faces = face_cascade.detectMultiScale(half_img, 1.3, 5)\n",
    "            if len(faces) == 1:\n",
    "                x, y, fw, fh = faces[0]\n",
    "                return save_resized_face(half_img[y:y+fh, x:x+fw], \"right\")\n",
    "\n",
    "    elif view_type == 'Speaker View':\n",
    "        faces = face_cascade.detectMultiScale(frame, 1.3, 5)\n",
    "        if len(faces) == 2:\n",
    "            face_areas = [(fw * fh, (x, y, fw, fh)) for (x, y, fw, fh) in faces]\n",
    "            face_areas.sort(reverse=True)\n",
    "            if option == 'Large':\n",
    "                x, y, fw, fh = face_areas[0][1]\n",
    "                return save_resized_face(frame[y:y+fh, x:x+fw], \"large\")\n",
    "            elif option == 'Small':\n",
    "                x, y, fw, fh = face_areas[1][1]\n",
    "                return save_resized_face(frame[y:y+fh, x:x+fw], \"small\")\n",
    "\n",
    "    return None\n",
    "\n",
    "def run_face_extraction(client_df, final_conversation_df, video_path, output_dir, view_value, option_value):\n",
    "    setup_output_folder(output_dir)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    for idx, row in client_df.iterrows():\n",
    "        cap.set(cv2.CAP_PROP_POS_MSEC, row['Mid_sec'] * 1000)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "        path = extract_face_from_frame(frame, view_value, option_value, idx, output_dir)\n",
    "        if path:\n",
    "            client_df.loc[idx, 'Image_Path'] = path\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if 'Image_Path' not in final_conversation_df.columns:\n",
    "        final_conversation_df['Image_Path'] = None\n",
    "    for idx in client_df.index:\n",
    "        final_conversation_df.at[idx, 'Image_Path'] = client_df.at[idx, 'Image_Path']\n",
    "\n",
    "    return final_conversation_df.copy()\n",
    "\n",
    "def show_dropdown_ui(callback_on_confirm):\n",
    "    selected_view = {'value': None}\n",
    "    selected_option = {'value': None}\n",
    "\n",
    "    view_dropdown = widgets.Dropdown(\n",
    "        options=['', 'Gallery View', 'Speaker View'],\n",
    "        description='Video View:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    option_dropdown = widgets.Dropdown(\n",
    "        options=[''],\n",
    "        description='Face Option:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    confirm_button = widgets.Button(description=\"Confirm Selection\", button_style='success')\n",
    "    output_area = widgets.Output()\n",
    "\n",
    "    def update_option_dropdown(change):\n",
    "        if change['new'] == 'Gallery View':\n",
    "            option_dropdown.options = ['', 'Left', 'Right']\n",
    "        elif change['new'] == 'Speaker View':\n",
    "            option_dropdown.options = ['', 'Large', 'Small']\n",
    "        else:\n",
    "            option_dropdown.options = ['']\n",
    "    view_dropdown.observe(update_option_dropdown, names='value')\n",
    "\n",
    "    def confirm_selection(b):\n",
    "        selected_view['value'] = view_dropdown.value\n",
    "        selected_option['value'] = option_dropdown.value\n",
    "        with output_area:\n",
    "            clear_output()\n",
    "            if selected_view['value'] and selected_option['value']:\n",
    "                print(f\"Selected View: {selected_view['value']} | Option: {selected_option['value']}\")\n",
    "                callback_on_confirm(selected_view['value'], selected_option['value'])\n",
    "            else:\n",
    "                print(\"Please select both dropdown values.\")\n",
    "\n",
    "    confirm_button.on_click(confirm_selection)\n",
    "    display(view_dropdown, option_dropdown, confirm_button, output_area)\n",
    "\n",
    "\n",
    "output_dir = r\"D:\\Data Science Projects Github\\ai-multimodal-emotion-therapy\\notebooks_code\\segmentation\\Extracted_Images\"\n",
    "client_df = prepare_client_df(final_conversation_df)\n",
    "\n",
    "def on_confirm(view_val, option_val):\n",
    "    post_df = run_face_extraction(client_df, final_conversation_df, video_path, output_dir, view_val, option_val)\n",
    "    display(post_df[['Start', 'End', 'Speaker', 'Text', 'Image_Path']].head())\n",
    "\n",
    "show_dropdown_ui(on_confirm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7b6941a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Text</th>\n",
       "      <th>Start_sec</th>\n",
       "      <th>End_sec</th>\n",
       "      <th>Mid_sec</th>\n",
       "      <th>Image_Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01:16</td>\n",
       "      <td>01:27</td>\n",
       "      <td>Client</td>\n",
       "      <td>And I'm a peer educator at CAPS here, and I t...</td>\n",
       "      <td>76</td>\n",
       "      <td>87</td>\n",
       "      <td>81.5</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01:53</td>\n",
       "      <td>02:08</td>\n",
       "      <td>Client</td>\n",
       "      <td>Um, so nothing much has changed in terms of w...</td>\n",
       "      <td>113</td>\n",
       "      <td>128</td>\n",
       "      <td>120.5</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02:08</td>\n",
       "      <td>02:21</td>\n",
       "      <td>Client</td>\n",
       "      <td>But as for the homework. I felt that sometime...</td>\n",
       "      <td>128</td>\n",
       "      <td>141</td>\n",
       "      <td>134.5</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>02:22</td>\n",
       "      <td>02:33</td>\n",
       "      <td>Client</td>\n",
       "      <td>and my thoughts were like controlling me. So ...</td>\n",
       "      <td>142</td>\n",
       "      <td>153</td>\n",
       "      <td>147.5</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>04:41</td>\n",
       "      <td>04:55</td>\n",
       "      <td>Client</td>\n",
       "      <td>So whenever I felt like my anxiety was throug...</td>\n",
       "      <td>281</td>\n",
       "      <td>295</td>\n",
       "      <td>288.0</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>04:56</td>\n",
       "      <td>05:08</td>\n",
       "      <td>Client</td>\n",
       "      <td>Like emails from my college about my GPA, fro...</td>\n",
       "      <td>296</td>\n",
       "      <td>308</td>\n",
       "      <td>302.0</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>05:38</td>\n",
       "      <td>05:52</td>\n",
       "      <td>Client</td>\n",
       "      <td>distract myself from like the initial thing t...</td>\n",
       "      <td>338</td>\n",
       "      <td>352</td>\n",
       "      <td>345.0</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>05:53</td>\n",
       "      <td>06:04</td>\n",
       "      <td>Client</td>\n",
       "      <td>tempted to like check whatever all the media ...</td>\n",
       "      <td>353</td>\n",
       "      <td>364</td>\n",
       "      <td>358.5</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>06:04</td>\n",
       "      <td>06:12</td>\n",
       "      <td>Client</td>\n",
       "      <td>racing. My thoughts are keep racing with ever...</td>\n",
       "      <td>364</td>\n",
       "      <td>372</td>\n",
       "      <td>368.0</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>09:53</td>\n",
       "      <td>10:04</td>\n",
       "      <td>Client</td>\n",
       "      <td>to myself in front of a mirror. And honestly,...</td>\n",
       "      <td>593</td>\n",
       "      <td>604</td>\n",
       "      <td>598.5</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13:46</td>\n",
       "      <td>13:53</td>\n",
       "      <td>Client</td>\n",
       "      <td>Yeah, I will definitely try to practice it, a...</td>\n",
       "      <td>826</td>\n",
       "      <td>833</td>\n",
       "      <td>829.5</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Start    End Speaker                                               Text  \\\n",
       "1   01:16  01:27  Client   And I'm a peer educator at CAPS here, and I t...   \n",
       "3   01:53  02:08  Client   Um, so nothing much has changed in terms of w...   \n",
       "4   02:08  02:21  Client   But as for the homework. I felt that sometime...   \n",
       "5   02:22  02:33  Client   and my thoughts were like controlling me. So ...   \n",
       "7   04:41  04:55  Client   So whenever I felt like my anxiety was throug...   \n",
       "8   04:56  05:08  Client   Like emails from my college about my GPA, fro...   \n",
       "10  05:38  05:52  Client   distract myself from like the initial thing t...   \n",
       "11  05:53  06:04  Client   tempted to like check whatever all the media ...   \n",
       "12  06:04  06:12  Client   racing. My thoughts are keep racing with ever...   \n",
       "14  09:53  10:04  Client   to myself in front of a mirror. And honestly,...   \n",
       "16  13:46  13:53  Client   Yeah, I will definitely try to practice it, a...   \n",
       "\n",
       "    Start_sec  End_sec  Mid_sec  \\\n",
       "1          76       87     81.5   \n",
       "3         113      128    120.5   \n",
       "4         128      141    134.5   \n",
       "5         142      153    147.5   \n",
       "7         281      295    288.0   \n",
       "8         296      308    302.0   \n",
       "10        338      352    345.0   \n",
       "11        353      364    358.5   \n",
       "12        364      372    368.0   \n",
       "14        593      604    598.5   \n",
       "16        826      833    829.5   \n",
       "\n",
       "                                           Image_Path  \n",
       "1   D:\\Data Science Projects Github\\ai-multimodal-...  \n",
       "3   D:\\Data Science Projects Github\\ai-multimodal-...  \n",
       "4   D:\\Data Science Projects Github\\ai-multimodal-...  \n",
       "5   D:\\Data Science Projects Github\\ai-multimodal-...  \n",
       "7   D:\\Data Science Projects Github\\ai-multimodal-...  \n",
       "8   D:\\Data Science Projects Github\\ai-multimodal-...  \n",
       "10  D:\\Data Science Projects Github\\ai-multimodal-...  \n",
       "11  D:\\Data Science Projects Github\\ai-multimodal-...  \n",
       "12  D:\\Data Science Projects Github\\ai-multimodal-...  \n",
       "14  D:\\Data Science Projects Github\\ai-multimodal-...  \n",
       "16  D:\\Data Science Projects Github\\ai-multimodal-...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf4b6ba",
   "metadata": {},
   "source": [
    "### Client/Patient Text Emotion Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d752a086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom DeBERTa model loaded.\n",
      "üîç Predicting speech-based emotions...\n",
      "Emotion prediction complete.\n"
     ]
    }
   ],
   "source": [
    "# Emotion mapping\n",
    "emotion_labels = {\n",
    "    0: \"Anger\", 1: \"Fear\", 2: \"Happy\", 3: \"Sadness\",\n",
    "    4: \"Neutral\", 5: \"Surprise\", 6: \"Confusion\", 7: \"Disgust\"\n",
    "}\n",
    "\n",
    "# Updated model class with dropout=0.3\n",
    "class WeightedDeBERTa(nn.Module):\n",
    "    def __init__(self, model_name, num_labels, class_weights):\n",
    "        super(WeightedDeBERTa, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.model = DebertaV2ForSequenceClassification.from_pretrained(\n",
    "            model_name, num_labels=num_labels\n",
    "        )\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = self.dropout(outputs.logits)\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = self.loss_fn(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            return SequenceClassifierOutput(loss=loss, logits=logits)\n",
    "        return SequenceClassifierOutput(logits=logits)\n",
    "\n",
    "# Main prediction function\n",
    "def add_speech_emotions_to_client_df(client_df, model_path):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Load tokenizer\n",
    "    tokenizer = DebertaV2TokenizerFast.from_pretrained(model_path, local_files_only=True)\n",
    "    print(\"Tokenizer loaded.\")\n",
    "\n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(os.path.join(model_path, 'custom_model.pth'))\n",
    "    class_weights = checkpoint['class_weights']\n",
    "\n",
    "    # Initialize and load model\n",
    "    model = WeightedDeBERTa(\n",
    "        \"microsoft/deberta-v3-small\",\n",
    "        num_labels=8,\n",
    "        class_weights=class_weights\n",
    "    ).to(device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    print(\"Custom DeBERTa model loaded.\")\n",
    "\n",
    "    # Set label mapping in model config\n",
    "    model.model.config.id2label = emotion_labels\n",
    "    model.model.config.label2id = {v: k for k, v in emotion_labels.items()}\n",
    "\n",
    "    def predict_emotion(text):\n",
    "        inputs = tokenizer(\n",
    "            text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "\n",
    "        if 'token_type_ids' in inputs:\n",
    "            del inputs['token_type_ids']\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs).logits\n",
    "            predicted_class = torch.argmax(logits, dim=-1).item()\n",
    "            return emotion_labels[predicted_class]\n",
    "\n",
    "    print(\"üîç Predicting speech-based emotions...\")\n",
    "    texts = client_df[\"Text\"].tolist()\n",
    "    predicted_emotions = [predict_emotion(text) for text in texts]\n",
    "    client_df[\"speech_predicted_emotion\"] = predicted_emotions\n",
    "\n",
    "    print(\"Emotion prediction complete.\")\n",
    "    return client_df\n",
    "\n",
    "model_path = r\"D:\\Data Science Projects Github\\ai-multimodal-emotion-therapy\\models\\deberta_model\"\n",
    "client_df = add_speech_emotions_to_client_df(client_df, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "568af326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Text</th>\n",
       "      <th>Image_Path</th>\n",
       "      <th>Start_sec</th>\n",
       "      <th>End_sec</th>\n",
       "      <th>Mid_sec</th>\n",
       "      <th>speech_predicted_emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01:16</td>\n",
       "      <td>01:27</td>\n",
       "      <td>Client</td>\n",
       "      <td>And I'm a peer educator at CAPS here, and I t...</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "      <td>76</td>\n",
       "      <td>87</td>\n",
       "      <td>81.5</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01:53</td>\n",
       "      <td>02:08</td>\n",
       "      <td>Client</td>\n",
       "      <td>Um, so nothing much has changed in terms of w...</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "      <td>113</td>\n",
       "      <td>128</td>\n",
       "      <td>120.5</td>\n",
       "      <td>Fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02:08</td>\n",
       "      <td>02:21</td>\n",
       "      <td>Client</td>\n",
       "      <td>But as for the homework. I felt that sometime...</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "      <td>128</td>\n",
       "      <td>141</td>\n",
       "      <td>134.5</td>\n",
       "      <td>Fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>02:22</td>\n",
       "      <td>02:33</td>\n",
       "      <td>Client</td>\n",
       "      <td>and my thoughts were like controlling me. So ...</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "      <td>142</td>\n",
       "      <td>153</td>\n",
       "      <td>147.5</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>04:41</td>\n",
       "      <td>04:55</td>\n",
       "      <td>Client</td>\n",
       "      <td>So whenever I felt like my anxiety was throug...</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "      <td>281</td>\n",
       "      <td>295</td>\n",
       "      <td>288.0</td>\n",
       "      <td>Fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>04:56</td>\n",
       "      <td>05:08</td>\n",
       "      <td>Client</td>\n",
       "      <td>Like emails from my college about my GPA, fro...</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "      <td>296</td>\n",
       "      <td>308</td>\n",
       "      <td>302.0</td>\n",
       "      <td>Fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>05:38</td>\n",
       "      <td>05:52</td>\n",
       "      <td>Client</td>\n",
       "      <td>distract myself from like the initial thing t...</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "      <td>338</td>\n",
       "      <td>352</td>\n",
       "      <td>345.0</td>\n",
       "      <td>Fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>05:53</td>\n",
       "      <td>06:04</td>\n",
       "      <td>Client</td>\n",
       "      <td>tempted to like check whatever all the media ...</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "      <td>353</td>\n",
       "      <td>364</td>\n",
       "      <td>358.5</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>06:04</td>\n",
       "      <td>06:12</td>\n",
       "      <td>Client</td>\n",
       "      <td>racing. My thoughts are keep racing with ever...</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "      <td>364</td>\n",
       "      <td>372</td>\n",
       "      <td>368.0</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>09:53</td>\n",
       "      <td>10:04</td>\n",
       "      <td>Client</td>\n",
       "      <td>to myself in front of a mirror. And honestly,...</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "      <td>593</td>\n",
       "      <td>604</td>\n",
       "      <td>598.5</td>\n",
       "      <td>Fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13:46</td>\n",
       "      <td>13:53</td>\n",
       "      <td>Client</td>\n",
       "      <td>Yeah, I will definitely try to practice it, a...</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "      <td>826</td>\n",
       "      <td>833</td>\n",
       "      <td>829.5</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Start    End Speaker                                               Text  \\\n",
       "1   01:16  01:27  Client   And I'm a peer educator at CAPS here, and I t...   \n",
       "3   01:53  02:08  Client   Um, so nothing much has changed in terms of w...   \n",
       "4   02:08  02:21  Client   But as for the homework. I felt that sometime...   \n",
       "5   02:22  02:33  Client   and my thoughts were like controlling me. So ...   \n",
       "7   04:41  04:55  Client   So whenever I felt like my anxiety was throug...   \n",
       "8   04:56  05:08  Client   Like emails from my college about my GPA, fro...   \n",
       "10  05:38  05:52  Client   distract myself from like the initial thing t...   \n",
       "11  05:53  06:04  Client   tempted to like check whatever all the media ...   \n",
       "12  06:04  06:12  Client   racing. My thoughts are keep racing with ever...   \n",
       "14  09:53  10:04  Client   to myself in front of a mirror. And honestly,...   \n",
       "16  13:46  13:53  Client   Yeah, I will definitely try to practice it, a...   \n",
       "\n",
       "                                           Image_Path  Start_sec  End_sec  \\\n",
       "1   D:\\Data Science Projects Github\\ai-multimodal-...         76       87   \n",
       "3   D:\\Data Science Projects Github\\ai-multimodal-...        113      128   \n",
       "4   D:\\Data Science Projects Github\\ai-multimodal-...        128      141   \n",
       "5   D:\\Data Science Projects Github\\ai-multimodal-...        142      153   \n",
       "7   D:\\Data Science Projects Github\\ai-multimodal-...        281      295   \n",
       "8   D:\\Data Science Projects Github\\ai-multimodal-...        296      308   \n",
       "10  D:\\Data Science Projects Github\\ai-multimodal-...        338      352   \n",
       "11  D:\\Data Science Projects Github\\ai-multimodal-...        353      364   \n",
       "12  D:\\Data Science Projects Github\\ai-multimodal-...        364      372   \n",
       "14  D:\\Data Science Projects Github\\ai-multimodal-...        593      604   \n",
       "16  D:\\Data Science Projects Github\\ai-multimodal-...        826      833   \n",
       "\n",
       "    Mid_sec speech_predicted_emotion  \n",
       "1      81.5                    Happy  \n",
       "3     120.5                     Fear  \n",
       "4     134.5                     Fear  \n",
       "5     147.5                    Anger  \n",
       "7     288.0                     Fear  \n",
       "8     302.0                     Fear  \n",
       "10    345.0                     Fear  \n",
       "11    358.5                  Neutral  \n",
       "12    368.0                    Happy  \n",
       "14    598.5                     Fear  \n",
       "16    829.5                    Happy  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78bf28a",
   "metadata": {},
   "source": [
    "#### Face Emotion Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a07403d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c032a4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Loading face emotion model...\n",
      "üîç Predicting emotions from images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aliir\\anaconda3\\envs\\whisperx\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\aliir\\anaconda3\\envs\\whisperx\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Face emotion predictions added to DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# Load trained ResNet18-based face emotion model\n",
    "def load_cv_emotion_model(weights_path):\n",
    "    model = models.resnet18(pretrained=False)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.BatchNorm1d(num_ftrs),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(num_ftrs, 8)\n",
    "    )\n",
    "    model.load_state_dict(torch.load(weights_path, map_location=torch.device('cpu')))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Transform for image preprocessing\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Predict emotion from image\n",
    "def predict_face_emotion(image_path, model):\n",
    "    try:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        image = image_transform(image).unsqueeze(0)  # (1, 3, 224, 224)\n",
    "        with torch.no_grad():\n",
    "            logits = model(image)\n",
    "            pred_class = torch.argmax(logits, dim=1).item()\n",
    "            return emotion_labels[pred_class]\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "        return \"Error\"\n",
    "\n",
    "# Main function to apply predictions to all rows\n",
    "def add_face_emotions_to_client_df(client_df, model_path):\n",
    "    print(\"üì¶ Loading face emotion model...\")\n",
    "    model = load_cv_emotion_model(model_path)\n",
    "\n",
    "    print(\"üîç Predicting emotions from images...\")\n",
    "    client_df[\"face_emotion_prediction\"] = client_df[\"Image_Path\"].apply(lambda path: predict_face_emotion(path, model))\n",
    "\n",
    "    print(\"‚úÖ Face emotion predictions added to DataFrame.\")\n",
    "    return client_df\n",
    "\n",
    "\n",
    "model_path = r\"D:\\Data Science Projects Github\\ai-multimodal-emotion-therapy\\models\\cv model\\best_model (1).pth\"\n",
    "client_df = add_face_emotions_to_client_df(client_df, model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3491a882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Text</th>\n",
       "      <th>Image_Path</th>\n",
       "      <th>Start_sec</th>\n",
       "      <th>End_sec</th>\n",
       "      <th>Mid_sec</th>\n",
       "      <th>speech_predicted_emotion</th>\n",
       "      <th>face_emotion_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01:16</td>\n",
       "      <td>01:27</td>\n",
       "      <td>Client</td>\n",
       "      <td>And I'm a peer educator at CAPS here, and I t...</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "      <td>76</td>\n",
       "      <td>87</td>\n",
       "      <td>81.5</td>\n",
       "      <td>Happy</td>\n",
       "      <td>Disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01:53</td>\n",
       "      <td>02:08</td>\n",
       "      <td>Client</td>\n",
       "      <td>Um, so nothing much has changed in terms of w...</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "      <td>113</td>\n",
       "      <td>128</td>\n",
       "      <td>120.5</td>\n",
       "      <td>Fear</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02:08</td>\n",
       "      <td>02:21</td>\n",
       "      <td>Client</td>\n",
       "      <td>But as for the homework. I felt that sometime...</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "      <td>128</td>\n",
       "      <td>141</td>\n",
       "      <td>134.5</td>\n",
       "      <td>Fear</td>\n",
       "      <td>Disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>02:22</td>\n",
       "      <td>02:33</td>\n",
       "      <td>Client</td>\n",
       "      <td>and my thoughts were like controlling me. So ...</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "      <td>142</td>\n",
       "      <td>153</td>\n",
       "      <td>147.5</td>\n",
       "      <td>Anger</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>04:41</td>\n",
       "      <td>04:55</td>\n",
       "      <td>Client</td>\n",
       "      <td>So whenever I felt like my anxiety was throug...</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "      <td>281</td>\n",
       "      <td>295</td>\n",
       "      <td>288.0</td>\n",
       "      <td>Fear</td>\n",
       "      <td>Disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>04:56</td>\n",
       "      <td>05:08</td>\n",
       "      <td>Client</td>\n",
       "      <td>Like emails from my college about my GPA, fro...</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "      <td>296</td>\n",
       "      <td>308</td>\n",
       "      <td>302.0</td>\n",
       "      <td>Fear</td>\n",
       "      <td>Disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>05:38</td>\n",
       "      <td>05:52</td>\n",
       "      <td>Client</td>\n",
       "      <td>distract myself from like the initial thing t...</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "      <td>338</td>\n",
       "      <td>352</td>\n",
       "      <td>345.0</td>\n",
       "      <td>Fear</td>\n",
       "      <td>Disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>05:53</td>\n",
       "      <td>06:04</td>\n",
       "      <td>Client</td>\n",
       "      <td>tempted to like check whatever all the media ...</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "      <td>353</td>\n",
       "      <td>364</td>\n",
       "      <td>358.5</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>06:04</td>\n",
       "      <td>06:12</td>\n",
       "      <td>Client</td>\n",
       "      <td>racing. My thoughts are keep racing with ever...</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "      <td>364</td>\n",
       "      <td>372</td>\n",
       "      <td>368.0</td>\n",
       "      <td>Happy</td>\n",
       "      <td>Disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>09:53</td>\n",
       "      <td>10:04</td>\n",
       "      <td>Client</td>\n",
       "      <td>to myself in front of a mirror. And honestly,...</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "      <td>593</td>\n",
       "      <td>604</td>\n",
       "      <td>598.5</td>\n",
       "      <td>Fear</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13:46</td>\n",
       "      <td>13:53</td>\n",
       "      <td>Client</td>\n",
       "      <td>Yeah, I will definitely try to practice it, a...</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "      <td>826</td>\n",
       "      <td>833</td>\n",
       "      <td>829.5</td>\n",
       "      <td>Happy</td>\n",
       "      <td>Disgust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Start    End Speaker                                               Text  \\\n",
       "1   01:16  01:27  Client   And I'm a peer educator at CAPS here, and I t...   \n",
       "3   01:53  02:08  Client   Um, so nothing much has changed in terms of w...   \n",
       "4   02:08  02:21  Client   But as for the homework. I felt that sometime...   \n",
       "5   02:22  02:33  Client   and my thoughts were like controlling me. So ...   \n",
       "7   04:41  04:55  Client   So whenever I felt like my anxiety was throug...   \n",
       "8   04:56  05:08  Client   Like emails from my college about my GPA, fro...   \n",
       "10  05:38  05:52  Client   distract myself from like the initial thing t...   \n",
       "11  05:53  06:04  Client   tempted to like check whatever all the media ...   \n",
       "12  06:04  06:12  Client   racing. My thoughts are keep racing with ever...   \n",
       "14  09:53  10:04  Client   to myself in front of a mirror. And honestly,...   \n",
       "16  13:46  13:53  Client   Yeah, I will definitely try to practice it, a...   \n",
       "\n",
       "                                           Image_Path  Start_sec  End_sec  \\\n",
       "1   D:\\Data Science Projects Github\\ai-multimodal-...         76       87   \n",
       "3   D:\\Data Science Projects Github\\ai-multimodal-...        113      128   \n",
       "4   D:\\Data Science Projects Github\\ai-multimodal-...        128      141   \n",
       "5   D:\\Data Science Projects Github\\ai-multimodal-...        142      153   \n",
       "7   D:\\Data Science Projects Github\\ai-multimodal-...        281      295   \n",
       "8   D:\\Data Science Projects Github\\ai-multimodal-...        296      308   \n",
       "10  D:\\Data Science Projects Github\\ai-multimodal-...        338      352   \n",
       "11  D:\\Data Science Projects Github\\ai-multimodal-...        353      364   \n",
       "12  D:\\Data Science Projects Github\\ai-multimodal-...        364      372   \n",
       "14  D:\\Data Science Projects Github\\ai-multimodal-...        593      604   \n",
       "16  D:\\Data Science Projects Github\\ai-multimodal-...        826      833   \n",
       "\n",
       "    Mid_sec speech_predicted_emotion face_emotion_prediction  \n",
       "1      81.5                    Happy                 Disgust  \n",
       "3     120.5                     Fear                 Neutral  \n",
       "4     134.5                     Fear                 Disgust  \n",
       "5     147.5                    Anger                 Sadness  \n",
       "7     288.0                     Fear                 Disgust  \n",
       "8     302.0                     Fear                 Disgust  \n",
       "10    345.0                     Fear                 Disgust  \n",
       "11    358.5                  Neutral                   Happy  \n",
       "12    368.0                    Happy                 Disgust  \n",
       "14    598.5                     Fear                   Happy  \n",
       "16    829.5                    Happy                 Disgust  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14883ff3",
   "metadata": {},
   "source": [
    "#### Testing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edf7c3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Video path\n",
    "video_path = r\"D:\\Data Science Projects Github\\ai-multimodal-emotion-therapy\\uploads\\Zoom practice therapy session.mp4\"\n",
    "\n",
    "# Model paths\n",
    "speaker_model_path = r\"D:\\Data Science Projects Github\\ai-multimodal-emotion-therapy\\models\\speaker_prediction_roberta_model\"\n",
    "text_model_path = r\"D:\\Data Science Projects Github\\ai-multimodal-emotion-therapy\\models\\deberta_model\"\n",
    "face_model_path = r\"D:\\Data Science Projects Github\\ai-multimodal-emotion-therapy\\models\\cv model\\best_model (1).pth\"\n",
    "\n",
    "# Output folder for extracted faces\n",
    "output_dir = r\"D:\\Data Science Projects Github\\ai-multimodal-emotion-therapy\\notebooks_code\\segmentation\\Extracted_Images\"\n",
    "\n",
    "# HF Token (if WhisperX diarization needs auth)\n",
    "hf_token = \"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5d2a2854",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline import (\n",
    "    transcribe_and_diarize,\n",
    "    load_speaker_model,\n",
    "    classify_and_map_speakers,\n",
    "    merge_conversation_segments,\n",
    "    extract_faces_for_client_segments,\n",
    "    add_speech_emotions_to_client_df,\n",
    "    add_face_emotions_to_client_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab0750d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'mp42', 'minor_version': '0', 'compatible_brands': 'isommp42', 'encoder': 'Google'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [640, 360], 'bitrate': 103, 'fps': 25.0, 'codec_name': 'h264', 'profile': '(Main)', 'metadata': {'Metadata': '', 'handler_name': 'ISO Media file produced by Google Inc.', 'vendor_id': '[0][0][0][0]'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': None, 'default': True, 'fps': 44100, 'bitrate': 95, 'metadata': {'Metadata': '', 'handler_name': 'ISO Media file produced by Google Inc.', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 691.91, 'bitrate': 202, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'h264', 'video_profile': '(Main)', 'video_size': [640, 360], 'video_bitrate': 103, 'video_fps': 25.0, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 44100, 'audio_bitrate': 95, 'video_duration': 691.91, 'video_n_frames': 17297}\n",
      "c:\\Users\\aliir\\anaconda3\\envs\\whisperx\\lib\\site-packages\\imageio_ffmpeg\\binaries\\ffmpeg-win-x86_64-v7.1.exe -i D:\\Data Science Projects Github\\ai-multimodal-emotion-therapy\\uploads\\Zoom practice therapy session.mp4 -loglevel error -f image2pipe -vf scale=640:360 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n",
      "MoviePy - Writing audio in D:\\Data Science Projects Github\\ai-multimodal-emotion-therapy\\uploads\\Zoom practice therapy session.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.5.1. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint c:\\Users\\aliir\\anaconda3\\envs\\whisperx\\lib\\site-packages\\whisperx\\assets\\pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No language specified, language will be first be detected for each audio file (increases inference time).\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.2. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.6.0+cu118. Bad things might happen unless you revert torch to 1.x.\n",
      "Detected language: en (1.00) in first 30s of audio...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aliir\\anaconda3\\envs\\whisperx\\lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1831.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start (sec)</th>\n",
       "      <th>End (sec)</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Text</th>\n",
       "      <th>total_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.031</td>\n",
       "      <td>9.920</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>what brought you here. Now go. Hi, Ms. Jalen....</td>\n",
       "      <td>9.889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.443</td>\n",
       "      <td>19.707</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>It's great to see you today. Let's start by r...</td>\n",
       "      <td>9.264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.517</td>\n",
       "      <td>28.685</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>Um, I have been struggling with anxiety, espe...</td>\n",
       "      <td>8.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.942</td>\n",
       "      <td>46.724</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>That makes sense. Yeah, it's important to und...</td>\n",
       "      <td>14.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47.129</td>\n",
       "      <td>61.068</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>Oh, I am aiming for being less anxious during...</td>\n",
       "      <td>13.939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Start (sec)  End (sec)     Speaker  \\\n",
       "0        0.031      9.920  SPEAKER_01   \n",
       "1       10.443     19.707  SPEAKER_01   \n",
       "2       20.517     28.685  SPEAKER_00   \n",
       "3       31.942     46.724  SPEAKER_01   \n",
       "4       47.129     61.068  SPEAKER_00   \n",
       "\n",
       "                                                Text  total_duration  \n",
       "0   what brought you here. Now go. Hi, Ms. Jalen....           9.889  \n",
       "1   It's great to see you today. Let's start by r...           9.264  \n",
       "2   Um, I have been struggling with anxiety, espe...           8.168  \n",
       "3   That makes sense. Yeah, it's important to und...          14.782  \n",
       "4   Oh, I am aiming for being less anxious during...          13.939  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transcript = transcribe_and_diarize(video_path, hf_token)\n",
    "df_transcript.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "140ee0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f3238544f547f1b98baac391ca5094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5841e6f01e40477391698659988f1131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/33 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "speaker_model, speaker_tokenizer, label_encoder = load_speaker_model(speaker_model_path, device=\"cuda\")\n",
    "df_mapped = classify_and_map_speakers(df_transcript, speaker_model, speaker_tokenizer, label_encoder, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "536e203f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00</td>\n",
       "      <td>00:19</td>\n",
       "      <td>therapist</td>\n",
       "      <td>what brought you here. Now go. Hi, Ms. Jalen....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:20</td>\n",
       "      <td>00:28</td>\n",
       "      <td>Client</td>\n",
       "      <td>Um, I have been struggling with anxiety, espe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:31</td>\n",
       "      <td>00:46</td>\n",
       "      <td>therapist</td>\n",
       "      <td>That makes sense. Yeah, it's important to und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:47</td>\n",
       "      <td>01:01</td>\n",
       "      <td>Client</td>\n",
       "      <td>Oh, I am aiming for being less anxious during...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01:04</td>\n",
       "      <td>01:15</td>\n",
       "      <td>therapist</td>\n",
       "      <td>Can you tell me more about situations where y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Start    End    Speaker                                               Text\n",
       "0  00:00  00:19  therapist   what brought you here. Now go. Hi, Ms. Jalen....\n",
       "1  00:20  00:28     Client   Um, I have been struggling with anxiety, espe...\n",
       "2  00:31  00:46  therapist   That makes sense. Yeah, it's important to und...\n",
       "3  00:47  01:01     Client   Oh, I am aiming for being less anxious during...\n",
       "4  01:04  01:15  therapist   Can you tell me more about situations where y..."
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = merge_conversation_segments(df_mapped)\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cd928b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_type = \"Gallery View\"  # or \"Speaker View\"\n",
    "face_option = \"Right\"        # Gallery: Left/Right, Speaker: Large/Small\n",
    "\n",
    "df_client = df_merged[df_merged[\"Speaker\"].str.lower() == \"client\"].copy()\n",
    "df_client = df_client.dropna()\n",
    "df_with_faces = extract_faces_for_client_segments(df_client, video_path, output_dir, view_type, face_option)\n",
    "df_with_faces = df_with_faces.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "79cfef5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Text</th>\n",
       "      <th>Start_sec</th>\n",
       "      <th>End_sec</th>\n",
       "      <th>Mid_sec</th>\n",
       "      <th>Image_Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:20</td>\n",
       "      <td>00:28</td>\n",
       "      <td>Client</td>\n",
       "      <td>Um, I have been struggling with anxiety, espe...</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>24.0</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:47</td>\n",
       "      <td>01:01</td>\n",
       "      <td>Client</td>\n",
       "      <td>Oh, I am aiming for being less anxious during...</td>\n",
       "      <td>47</td>\n",
       "      <td>61</td>\n",
       "      <td>54.0</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>02:00</td>\n",
       "      <td>02:10</td>\n",
       "      <td>Client</td>\n",
       "      <td>I would say that it's been somewhat helpful. ...</td>\n",
       "      <td>120</td>\n",
       "      <td>130</td>\n",
       "      <td>125.0</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>02:25</td>\n",
       "      <td>02:37</td>\n",
       "      <td>Client</td>\n",
       "      <td>I think the breathing exercises have been rea...</td>\n",
       "      <td>145</td>\n",
       "      <td>157</td>\n",
       "      <td>151.0</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>03:00</td>\n",
       "      <td>03:12</td>\n",
       "      <td>Client</td>\n",
       "      <td>Um, I would say that I'm probably in the prep...</td>\n",
       "      <td>180</td>\n",
       "      <td>192</td>\n",
       "      <td>186.0</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Start    End Speaker                                               Text  \\\n",
       "1   00:20  00:28  Client   Um, I have been struggling with anxiety, espe...   \n",
       "3   00:47  01:01  Client   Oh, I am aiming for being less anxious during...   \n",
       "7   02:00  02:10  Client   I would say that it's been somewhat helpful. ...   \n",
       "9   02:25  02:37  Client   I think the breathing exercises have been rea...   \n",
       "11  03:00  03:12  Client   Um, I would say that I'm probably in the prep...   \n",
       "\n",
       "    Start_sec  End_sec  Mid_sec  \\\n",
       "1          20       28     24.0   \n",
       "3          47       61     54.0   \n",
       "7         120      130    125.0   \n",
       "9         145      157    151.0   \n",
       "11        180      192    186.0   \n",
       "\n",
       "                                           Image_Path  \n",
       "1   D:\\Data Science Projects Github\\ai-multimodal-...  \n",
       "3   D:\\Data Science Projects Github\\ai-multimodal-...  \n",
       "7   D:\\Data Science Projects Github\\ai-multimodal-...  \n",
       "9   D:\\Data Science Projects Github\\ai-multimodal-...  \n",
       "11  D:\\Data Science Projects Github\\ai-multimodal-...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_faces.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5a1f47f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "d:\\Data Science Projects Github\\ai-multimodal-emotion-therapy\\notebooks_code\\segmentation\\pipeline.py:231: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  client_df[\"speech_predicted_emotion\"] = client_df[\"Text\"].apply(predict_emotion)\n",
      "c:\\Users\\aliir\\anaconda3\\envs\\whisperx\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\aliir\\anaconda3\\envs\\whisperx\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "d:\\Data Science Projects Github\\ai-multimodal-emotion-therapy\\notebooks_code\\segmentation\\pipeline.py:258: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  client_df[\"face_emotion_prediction\"] = client_df[\"Image_Path\"].apply(predict_emotion)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Text</th>\n",
       "      <th>Start_sec</th>\n",
       "      <th>End_sec</th>\n",
       "      <th>Mid_sec</th>\n",
       "      <th>Image_Path</th>\n",
       "      <th>speech_predicted_emotion</th>\n",
       "      <th>face_emotion_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:20</td>\n",
       "      <td>00:28</td>\n",
       "      <td>Client</td>\n",
       "      <td>Um, I have been struggling with anxiety, espe...</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>24.0</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "      <td>Confusion</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:47</td>\n",
       "      <td>01:01</td>\n",
       "      <td>Client</td>\n",
       "      <td>Oh, I am aiming for being less anxious during...</td>\n",
       "      <td>47</td>\n",
       "      <td>61</td>\n",
       "      <td>54.0</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "      <td>Fear</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>02:00</td>\n",
       "      <td>02:10</td>\n",
       "      <td>Client</td>\n",
       "      <td>I would say that it's been somewhat helpful. ...</td>\n",
       "      <td>120</td>\n",
       "      <td>130</td>\n",
       "      <td>125.0</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "      <td>Fear</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>02:25</td>\n",
       "      <td>02:37</td>\n",
       "      <td>Client</td>\n",
       "      <td>I think the breathing exercises have been rea...</td>\n",
       "      <td>145</td>\n",
       "      <td>157</td>\n",
       "      <td>151.0</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>03:00</td>\n",
       "      <td>03:12</td>\n",
       "      <td>Client</td>\n",
       "      <td>Um, I would say that I'm probably in the prep...</td>\n",
       "      <td>180</td>\n",
       "      <td>192</td>\n",
       "      <td>186.0</td>\n",
       "      <td>D:\\Data Science Projects Github\\ai-multimodal-...</td>\n",
       "      <td>Confusion</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Start    End Speaker                                               Text  \\\n",
       "1   00:20  00:28  Client   Um, I have been struggling with anxiety, espe...   \n",
       "3   00:47  01:01  Client   Oh, I am aiming for being less anxious during...   \n",
       "7   02:00  02:10  Client   I would say that it's been somewhat helpful. ...   \n",
       "9   02:25  02:37  Client   I think the breathing exercises have been rea...   \n",
       "11  03:00  03:12  Client   Um, I would say that I'm probably in the prep...   \n",
       "\n",
       "    Start_sec  End_sec  Mid_sec  \\\n",
       "1          20       28     24.0   \n",
       "3          47       61     54.0   \n",
       "7         120      130    125.0   \n",
       "9         145      157    151.0   \n",
       "11        180      192    186.0   \n",
       "\n",
       "                                           Image_Path  \\\n",
       "1   D:\\Data Science Projects Github\\ai-multimodal-...   \n",
       "3   D:\\Data Science Projects Github\\ai-multimodal-...   \n",
       "7   D:\\Data Science Projects Github\\ai-multimodal-...   \n",
       "9   D:\\Data Science Projects Github\\ai-multimodal-...   \n",
       "11  D:\\Data Science Projects Github\\ai-multimodal-...   \n",
       "\n",
       "   speech_predicted_emotion face_emotion_prediction  \n",
       "1                 Confusion                   Anger  \n",
       "3                      Fear                 Sadness  \n",
       "7                      Fear                   Anger  \n",
       "9                     Happy                 Sadness  \n",
       "11                Confusion                 Neutral  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_text_emotion = add_speech_emotions_to_client_df(df_with_faces, text_model_path)\n",
    "df_final = add_face_emotions_to_client_df(df_with_text_emotion, face_model_path)\n",
    "df_final.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisperx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
