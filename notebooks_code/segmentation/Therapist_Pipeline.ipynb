{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\")\n",
    "assert torch.cuda.is_available(), \"CUDA GPU is not available. Please check your setup.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "csv_path = r\"C:\\Users\\sanke\\Desktop\\Therapist_Model\\Segmentation Data\\Data\\Final Data\\session_transcript.csv\"\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model and tokenizer\n",
    "model_dir = r\"C:\\Users\\sanke\\Desktop\\Therapist_Model\\Saved Model\"\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_dir)\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_dir)\n",
    "label_encoder = joblib.load(os.path.join(model_dir, \"label_encoder.pkl\"))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c703241c7dab4a9796bc3d49e8d97bb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/63 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8daedb9dac674bbdb0d29be2335b3218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prediction function\n",
    "def predict_speaker_class(df_subset):\n",
    "    dataset = Dataset.from_pandas(df_subset[[\"Text\"]].rename(columns={\"Text\": \"utterance\"}))\n",
    "    dataset = dataset.map(lambda x: tokenizer(x[\"utterance\"], padding=\"max_length\", truncation=True, max_length=512), batched=True)\n",
    "    dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "    loader = DataLoader(dataset, batch_size=16)\n",
    "\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            preds = torch.argmax(outputs.logits, axis=-1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "\n",
    "    predicted_labels = label_encoder.inverse_transform(all_preds)\n",
    "    return predicted_labels\n",
    "\n",
    "# Predict for SPEAKER_00\n",
    "speaker_00_df = df[df[\"Speaker\"] == \"SPEAKER_00\"].copy()\n",
    "speaker_00_preds = predict_speaker_class(speaker_00_df)\n",
    "speaker_00_df[\"Predicted\"] = speaker_00_preds\n",
    "majority_00 = speaker_00_df[\"Predicted\"].value_counts().idxmax()\n",
    "percent_00 = (speaker_00_df[\"Predicted\"].value_counts()[majority_00] / len(speaker_00_df)) * 100\n",
    "\n",
    "# Predict for SPEAKER_01\n",
    "speaker_01_df = df[df[\"Speaker\"] == \"SPEAKER_01\"].copy()\n",
    "speaker_01_preds = predict_speaker_class(speaker_01_df)\n",
    "speaker_01_df[\"Predicted\"] = speaker_01_preds\n",
    "majority_01 = speaker_01_df[\"Predicted\"].value_counts().idxmax()\n",
    "percent_01 = (speaker_01_df[\"Predicted\"].value_counts()[majority_01] / len(speaker_01_df)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Summary:\n",
      "SPEAKER_00 → Majority class: Client, Confidence: 55.56%\n",
      "SPEAKER_01 → Majority class: Client, Confidence: 100.00%\n",
      "\n",
      "Selected Mapping Based on Higher Confidence: {'SPEAKER_01': 'Client', 'SPEAKER_00': 'therapist'}\n",
      "\n",
      "0     therapist\n",
      "1     therapist\n",
      "2     therapist\n",
      "3     therapist\n",
      "4     therapist\n",
      "5     therapist\n",
      "6     therapist\n",
      "7        Client\n",
      "8     therapist\n",
      "9     therapist\n",
      "10       Client\n",
      "11       Client\n",
      "12       Client\n",
      "13    therapist\n",
      "14    therapist\n",
      "15    therapist\n",
      "16    therapist\n",
      "17    therapist\n",
      "18    therapist\n",
      "19    therapist\n",
      "Name: Speaker, dtype: object\n",
      "   Start (sec)  End (sec)    Speaker\n",
      "0        1.837     10.055  therapist\n",
      "1       10.055     19.454  therapist\n",
      "2       19.454     30.440  therapist\n",
      "3       30.440     44.497  therapist\n",
      "4       44.497     52.580  therapist\n",
      "5       52.580     61.456  therapist\n",
      "6       61.456     76.340  therapist\n",
      "7       76.829     87.258     Client\n",
      "8       87.595     99.610  therapist\n",
      "9       99.610    113.178  therapist\n"
     ]
    }
   ],
   "source": [
    "# Decide which speaker has higher majority confidence\n",
    "if percent_00 > percent_01:\n",
    "    speaker_map = {\n",
    "        \"SPEAKER_00\": majority_00,\n",
    "        \"SPEAKER_01\": \"therapist\" if majority_00.lower() == \"client\" else \"client\"\n",
    "    }\n",
    "else:\n",
    "    speaker_map = {\n",
    "        \"SPEAKER_01\": majority_01,\n",
    "        \"SPEAKER_00\": \"therapist\" if majority_01.lower() == \"client\" else \"client\"\n",
    "    }\n",
    "\n",
    "# Apply speaker mapping\n",
    "updated_df = df.copy()\n",
    "updated_df[\"Speaker\"] = updated_df[\"Speaker\"].replace(speaker_map)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nPrediction Summary:\")\n",
    "print(f\"SPEAKER_00 → Majority class: {majority_00}, Confidence: {percent_00:.2f}%\")\n",
    "print(f\"SPEAKER_01 → Majority class: {majority_01}, Confidence: {percent_01:.2f}%\")\n",
    "print(f\"\\nSelected Mapping Based on Higher Confidence: {speaker_map}\\n\")\n",
    "print(updated_df[\"Speaker\"].head(20))\n",
    "print(updated_df.iloc[:10, :3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to convert seconds to MM:SS format\n",
    "def sec_to_min_sec(seconds):\n",
    "    minutes = int(seconds) // 60\n",
    "    seconds = int(seconds) % 60\n",
    "    return f\"{minutes:02d}:{seconds:02d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize with the first row\n",
    "merged_data = []\n",
    "current_speaker = updated_df.loc[0, 'Speaker']\n",
    "current_start = updated_df.loc[0, 'Start (sec)']\n",
    "current_end = updated_df.loc[0, 'End (sec)']\n",
    "current_text = updated_df.loc[0, 'Text']\n",
    "\n",
    "# Iterate through rows to merge consecutive therapist segments, keeping client entries separate\n",
    "for i in range(1, len(updated_df)):\n",
    "    row = updated_df.loc[i]\n",
    "    speaker = row['Speaker']\n",
    "    if speaker == \"therapist\" and current_speaker == \"therapist\":\n",
    "        current_end = row['End (sec)']\n",
    "        current_text += \" \" + row['Text']\n",
    "    else:\n",
    "        merged_data.append({\n",
    "            'Start': sec_to_min_sec(current_start),\n",
    "            'End': sec_to_min_sec(current_end),\n",
    "            'Speaker': current_speaker,\n",
    "            'Text': current_text\n",
    "        })\n",
    "        current_speaker = speaker\n",
    "        current_start = row['Start (sec)']\n",
    "        current_end = row['End (sec)']\n",
    "        current_text = row['Text']\n",
    "merged_data.append({\n",
    "    'Start': sec_to_min_sec(current_start),\n",
    "    'End': sec_to_min_sec(current_end),\n",
    "    'Speaker': current_speaker,\n",
    "    'Text': current_text\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Start    End    Speaker                                               Text\n",
      "0  00:01  01:16  therapist   All right, hi everybody. My name is Daniel Ga...\n",
      "1  01:16  01:27     Client   And I'm a peer educator at CAPS here, and I t...\n",
      "2  01:27  01:53  therapist   All right, so we're going to go ahead and div...\n",
      "3  01:53  02:08     Client   Um, so nothing much has changed in terms of w...\n",
      "4  02:08  02:21     Client   But as for the homework. I felt that sometime...\n",
      "5  02:22  02:33     Client   and my thoughts were like controlling me. So ...\n",
      "6  02:33  04:40  therapist   the same thing going on every day, right? Rig...\n",
      "7  04:41  04:55     Client   So whenever I felt like my anxiety was throug...\n",
      "8  04:56  05:08     Client   Like emails from my college about my GPA, fro...\n",
      "9  05:09  05:37  therapist   And it just like builds up so I can't even co...\n"
     ]
    }
   ],
   "source": [
    "# Create the final conversation DataFrame\n",
    "final_conversation_df = pd.DataFrame(merged_data)\n",
    "print(final_conversation_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final conversation CSV already exists at C:\\Users\\sanke\\Desktop\\Therapist_Model\\Segmentation Data\\Data\\Final Data\\Final_Conversation.csv, skipping save.\n"
     ]
    }
   ],
   "source": [
    "# Save final conversation data only if it does not exist\n",
    "final_data_dir = r\"C:\\Users\\sanke\\Desktop\\Therapist_Model\\Segmentation Data\\Data\\Final Data\"\n",
    "os.makedirs(final_data_dir, exist_ok=True)\n",
    "final_data_path = os.path.join(final_data_dir, \"Final_Conversation.csv\")\n",
    "if not os.path.exists(final_data_path):\n",
    "    final_conversation_df.to_csv(final_data_path, index=False)\n",
    "    print(f\"Final conversation data saved to {final_data_path}\")\n",
    "else:\n",
    "    print(f\"Final conversation CSV already exists at {final_data_path}, skipping save.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
